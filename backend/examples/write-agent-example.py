import os
import time
from typing import TypedDict, Annotated, List, Dict, Optional
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import operator
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT


# ============================================
# 1. é…ç½® API
# ============================================

class LLMConfig:
    """LLMé…ç½®ç±»,æ”¯æŒè‡ªå®šä¹‰API Keyå’ŒAPI URL"""

    def __init__(
            self,
            api_key: str,
            api_url: str = None,
            model: str = "gpt-4",
            max_retries: int = 3,
            timeout: int = 60
    ):
        self.api_key = api_key
        self.api_url = api_url or "https://api.openai.com/v1"
        self.model = model
        self.max_retries = max_retries
        self.timeout = timeout

    def get_llm(self, temperature: float = 0.7):
        """è·å–é…ç½®å¥½çš„LLMå®ä¾‹"""
        return ChatOpenAI(
            model=self.model,
            temperature=temperature,
            api_key=self.api_key,
            base_url=self.api_url,
            max_retries=self.max_retries,
            timeout=self.timeout
        )


# ============================================
# 2. å®šä¹‰çŠ¶æ€
# ============================================

class DocumentState(TypedDict):
    """æ–‡æ¡£ç”ŸæˆçŠ¶æ€"""
    user_request: str
    analysis: str
    assigned_expert: str
    outline: List[Dict[str, str]]
    section_assignments: Dict[str, str]
    completed_sections: Annotated[List[Dict[str, str]], operator.add]
    section_summaries: Annotated[List[Dict[str, str]], operator.add]  # æ–°å¢ï¼šç« èŠ‚æ¦‚è¿°åˆ—è¡¨
    final_document: str
    llm_config: LLMConfig
    error_message: Optional[str]


# ============================================
# 3. å®šä¹‰ä¸“å®¶ç±»å‹
# ============================================

EXPERT_TYPES = {
    "computer_science": {
        "name": "è®¡ç®—æœºç§‘å­¦ä¸“å®¶",
        "description": "æ“…é•¿è½¯ä»¶å¼€å‘ã€ç®—æ³•ã€ç³»ç»Ÿæ¶æ„ã€äººå·¥æ™ºèƒ½ç­‰æŠ€æœ¯é¢†åŸŸ"
    },
    "legal_contract": {
        "name": "æ³•å¾‹åˆåŒä¸“å®¶",
        "description": "æ“…é•¿åˆåŒèµ·è‰ã€æ³•å¾‹æ¡æ¬¾ã€åˆè§„å®¡æŸ¥ã€çŸ¥è¯†äº§æƒç­‰æ³•å¾‹äº‹åŠ¡"
    },
    "business_plan": {
        "name": "å•†ä¸šè®¡åˆ’ä¸“å®¶",
        "description": "æ“…é•¿å•†ä¸šç­–ç•¥ã€å¸‚åœºåˆ†æã€è´¢åŠ¡è§„åˆ’ã€å•†ä¸šæ¨¡å¼è®¾è®¡"
    },
    "medical_health": {
        "name": "åŒ»ç–—å¥åº·ä¸“å®¶",
        "description": "æ“…é•¿åŒ»å­¦çŸ¥è¯†ã€å¥åº·ç®¡ç†ã€åŒ»ç–—æ”¿ç­–ã€ä¸´åºŠç ”ç©¶"
    },
    "finance_investment": {
        "name": "é‡‘èæŠ•èµ„ä¸“å®¶",
        "description": "æ“…é•¿æŠ•èµ„åˆ†æã€é‡‘èäº§å“ã€é£é™©ç®¡ç†ã€èµ„äº§é…ç½®"
    },
    "marketing_branding": {
        "name": "å¸‚åœºè¥é”€ä¸“å®¶",
        "description": "æ“…é•¿å“ç‰Œç­–åˆ’ã€å¸‚åœºæ¨å¹¿ã€ç”¨æˆ·å¢é•¿ã€å†…å®¹è¥é”€"
    },
    "education_training": {
        "name": "æ•™è‚²åŸ¹è®­ä¸“å®¶",
        "description": "æ“…é•¿è¯¾ç¨‹è®¾è®¡ã€æ•™å­¦æ–¹æ³•ã€åŸ¹è®­ä½“ç³»ã€æ•™è‚²æŠ€æœ¯"
    },
    "research_academic": {
        "name": "å­¦æœ¯ç ”ç©¶ä¸“å®¶",
        "description": "æ“…é•¿å­¦æœ¯å†™ä½œã€ç ”ç©¶æ–¹æ³•ã€æ–‡çŒ®ç»¼è¿°ã€è®ºæ–‡æ’°å†™"
    }
}


# ============================================
# 4. è¾…åŠ©å‡½æ•°
# ============================================

def safe_llm_invoke(llm, messages, retry_count=3, delay=2):
    """å®‰å…¨çš„LLMè°ƒç”¨,å¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(retry_count):
        try:
            response = llm.invoke(messages)
            return response
        except Exception as e:
            print(f"âš ï¸  APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{retry_count}): {str(e)}")
            if attempt < retry_count - 1:
                wait_time = delay * (attempt + 1)
                print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥,å·²é‡è¯•{retry_count}æ¬¡: {str(e)}")


# ============================================
# 5. å·¥ä½œæµèŠ‚ç‚¹å‡½æ•°
# ============================================

def analyze_request(state: DocumentState) -> DocumentState:
    """åˆ†æä¸“å®¶:åˆ†æç”¨æˆ·è¯·æ±‚å¹¶æŒ‡æ´¾åˆé€‚çš„é¢†åŸŸä¸“å®¶"""
    try:
        llm = state["llm_config"].get_llm(temperature=0.3)

        expert_list = "\n".join([
            f"- {key}: {info['name']} - {info['description']}"
            for key, info in EXPERT_TYPES.items()
        ])

        prompt = f"""ä½ æ˜¯ä¸€ä½åˆ†æä¸“å®¶,éœ€è¦åˆ†æç”¨æˆ·çš„æ–‡æ¡£éœ€æ±‚å¹¶æŒ‡æ´¾åˆé€‚çš„é¢†åŸŸä¸“å®¶ã€‚

        å¯é€‰çš„ä¸“å®¶ç±»å‹:
        {expert_list}

        ç”¨æˆ·è¯·æ±‚:{state['user_request']}

        è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡:
        1. åˆ†æç”¨æˆ·è¯·æ±‚çš„æ ¸å¿ƒä¸»é¢˜å’Œç›®æ ‡
        2. è¯†åˆ«æ¶‰åŠçš„ä¸»è¦é¢†åŸŸ
        3. é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä½ä¸»è¦ä¸“å®¶æ¥è´Ÿè´£è¿™ä¸ªæ–‡æ¡£
        4. ç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä½ä¸“å®¶

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡º:
        åˆ†æ:[ä½ çš„åˆ†æ]
        æŒ‡æ´¾ä¸“å®¶:[ä¸“å®¶ç±»å‹çš„key,å¦‚computer_science]
        ç†ç”±:[é€‰æ‹©ç†ç”±]"""

        messages = [SystemMessage(content=prompt)]
        response = safe_llm_invoke(llm, messages)

        analysis_text = response.content

        assigned_expert = "computer_science"
        for line in analysis_text.split("\n"):
            if "æŒ‡æ´¾ä¸“å®¶:" in line or "æŒ‡æ´¾ä¸“å®¶:" in line:
                expert_key = line.split(":")[-1].split(":")[-1].strip()
                if expert_key in EXPERT_TYPES:
                    assigned_expert = expert_key
                    break

        state["analysis"] = analysis_text
        state["assigned_expert"] = assigned_expert

        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š åˆ†æé˜¶æ®µå®Œæˆ")
        print(f"{'=' * 60}")
        print(f"åˆ†æç»“æœ:\n{analysis_text}\n")

        return state

    except Exception as e:
        print(f"âŒ åˆ†æé˜¶æ®µå‡ºé”™: {str(e)}")
        state["error_message"] = f"åˆ†æé˜¶æ®µé”™è¯¯: {str(e)}"
        raise


def create_outline(state: DocumentState) -> DocumentState:
    """ä¸»è¦ä¸“å®¶:åˆ›å»ºæ–‡æ¡£å¤§çº²"""
    try:
        llm = state["llm_config"].get_llm(temperature=0.5)

        expert_info = EXPERT_TYPES[state["assigned_expert"]]

        prompt = f"""ä½ æ˜¯ä¸€ä½{expert_info['name']},{expert_info['description']}ã€‚

        ç”¨æˆ·è¯·æ±‚:{state['user_request']}

        åˆ†æç»“æœ:{state['analysis']}

        è¯·ä¸ºè¿™ä»½æ–‡æ¡£åˆ›å»ºè¯¦ç»†çš„å¤§çº²ã€‚å¤§çº²åº”è¯¥åŒ…å«2-3ä¸ªä¸»è¦ç« èŠ‚,æ¯ä¸ªç« èŠ‚éƒ½æœ‰æ˜ç¡®çš„ä¸»é¢˜ã€‚

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸ªç« èŠ‚(æ¯è¡Œä¸€ä¸ªç« èŠ‚):
        ç¬¬1ç« :[ç« èŠ‚æ ‡é¢˜] | [ç®€è¦æè¿°] | [å»ºè®®ä¸“å®¶ç±»å‹]
        ç¬¬2ç« :[ç« èŠ‚æ ‡é¢˜] | [ç®€è¦æè¿°] | [å»ºè®®ä¸“å®¶ç±»å‹]
        ...

        å»ºè®®ä¸“å®¶ç±»å‹è¯·ä»ä»¥ä¸‹é€‰æ‹©:{', '.join(EXPERT_TYPES.keys())}"""

        messages = [SystemMessage(content=prompt)]
        response = safe_llm_invoke(llm, messages)

        outline = []
        for line in response.content.split("\n"):
            if line.strip() and "ç¬¬" in line and "ç« " in line:
                parts = line.split("|")
                if len(parts) >= 3:
                    title = parts[0].strip()
                    description = parts[1].strip()
                    expert = parts[2].strip()

                    expert_key = expert
                    for key in EXPERT_TYPES.keys():
                        if key in expert.lower():
                            expert_key = key
                            break

                    outline.append({
                        "title": title,
                        "description": description,
                        "expert": expert_key
                    })

        if not outline:
            outline = [
                {
                    "title": f"ç¬¬1ç« :{state['user_request']}æ¦‚è¿°",
                    "description": "æ–‡æ¡£ä¸»é¢˜çš„æ•´ä½“ä»‹ç»",
                    "expert": state["assigned_expert"]
                },
                {
                    "title": "ç¬¬2ç« :æ ¸å¿ƒå†…å®¹",
                    "description": "è¯¦ç»†é˜è¿°ä¸»è¦å†…å®¹",
                    "expert": state["assigned_expert"]
                },
                {
                    "title": "ç¬¬3ç« :æ€»ç»“ä¸å±•æœ›",
                    "description": "æ€»ç»“è¦ç‚¹å¹¶å±•æœ›æœªæ¥",
                    "expert": state["assigned_expert"]
                }
            ]

        state["outline"] = outline

        print(f"\n{'=' * 60}")
        print(f"ğŸ“ å¤§çº²åˆ›å»ºå®Œæˆ")
        print(f"{'=' * 60}")
        for item in outline:
            print(f"{item['title']}")
            print(f"  æè¿°: {item['description']}")
            print(f"  ä¸“å®¶: {EXPERT_TYPES[item['expert']]['name']}\n")

        return state

    except Exception as e:
        print(f"âŒ å¤§çº²åˆ›å»ºå‡ºé”™: {str(e)}")
        state["error_message"] = f"å¤§çº²åˆ›å»ºé”™è¯¯: {str(e)}"
        raise


def assign_sections(state: DocumentState) -> DocumentState:
    """åˆ†é…ç« èŠ‚ç»™ä¸åŒçš„ä¸“å®¶"""
    assignments = {}
    for i, section in enumerate(state["outline"]):
        section_id = f"section_{i + 1}"
        assignments[section_id] = section["expert"]

    state["section_assignments"] = assignments
    if "completed_sections" not in state:
        state["completed_sections"] = []
    if "section_summaries" not in state:
        state["section_summaries"] = []

    return state


def write_section(state: DocumentState) -> DocumentState:
    """é¢†åŸŸä¸“å®¶:ç¼–å†™å…·ä½“ç« èŠ‚"""
    try:
        completed_count = len(state.get("completed_sections", []))

        if completed_count >= len(state["outline"]):
            return state

        section = state["outline"][completed_count]
        expert_type = section["expert"]
        expert_info = EXPERT_TYPES[expert_type]

        llm = state["llm_config"].get_llm(temperature=0.7)

        # æ„å»ºä¹‹å‰ç« èŠ‚çš„æ¦‚è¿°ä¸Šä¸‹æ–‡
        previous_summaries = ""
        if state.get("section_summaries"):
            previous_summaries = "\n\nå·²å®Œæˆç« èŠ‚çš„æ¦‚è¿°:\n"
            for i, summary in enumerate(state["section_summaries"]):
                previous_summaries += f"\n{summary['title']}\næ¦‚è¿°: {summary['summary']}\n"

        prompt = f"""ä½ æ˜¯ä¸€ä½{expert_info['name']},{expert_info['description']}ã€‚

æ•´ä½“æ–‡æ¡£ä¸»é¢˜:{state['user_request']}

æ•´ä½“åˆ†æ:{state['analysis']}
{previous_summaries}

ä½ éœ€è¦ç¼–å†™çš„ç« èŠ‚:
{section['title']}
ç« èŠ‚æè¿°:{section['description']}

è¯·ç¼–å†™è¿™ä¸€ç« èŠ‚çš„è¯¦ç»†å†…å®¹,è¦æ±‚:
1. å†…å®¹ä¸“ä¸šã€è¯¦å®ã€æœ‰æ·±åº¦
2. é€»è¾‘æ¸…æ™°,ç»“æ„åˆç†
3. å­—æ•°åœ¨800-1500å­—ä¹‹é—´
4. åŒ…å«å…·ä½“çš„æ¡ˆä¾‹ã€æ•°æ®æˆ–æ–¹æ³•(å¦‚é€‚ç”¨)
5. ä¸ä¹‹å‰çš„ç« èŠ‚ä¿æŒè¿è´¯æ€§å’Œä¸€è‡´æ€§

è¯·ç›´æ¥è¾“å‡ºç« èŠ‚å†…å®¹,ä¸éœ€è¦é‡å¤ç« èŠ‚æ ‡é¢˜ã€‚"""

        messages = [SystemMessage(content=prompt)]
        response = safe_llm_invoke(llm, messages)

        completed_section = {
            "title": section["title"],
            "content": response.content,
            "expert": expert_type
        }

        print(f"\n{'=' * 60}")
        print(f"âœï¸  ç« èŠ‚ç¼–å†™å®Œæˆ ({completed_count + 1}/{len(state['outline'])}): {section['title']}")
        print(f"   ä¸“å®¶: {expert_info['name']}")
        print(f"   å­—æ•°: {len(response.content)}")
        print(f"{'=' * 60}\n")

        # ç”Ÿæˆç« èŠ‚æ¦‚è¿°
        summary = generate_section_summary(
            llm=llm,
            section_title=section["title"],
            section_content=response.content,
            expert_name=expert_info['name']
        )

        section_summary = {
            "title": section["title"],
            "summary": summary
        }

        print(f"ğŸ“‹ ç« èŠ‚æ¦‚è¿°å·²ç”Ÿæˆ ({len(summary)}å­—)\n")
        print(f"æ¦‚è¿°å†…å®¹:\n{summary}\n")

        return {
            "completed_sections": [completed_section],
            "section_summaries": [section_summary]
        }

    except Exception as e:
        print(f"âŒ ç« èŠ‚ç¼–å†™å‡ºé”™: {str(e)}")
        state["error_message"] = f"ç« èŠ‚ç¼–å†™é”™è¯¯: {str(e)}"
        raise


def generate_section_summary(llm, section_title: str, section_content: str, expert_name: str) -> str:
    """
    ç”Ÿæˆç« èŠ‚çš„300å­—æ¦‚è¿°

    å‚æ•°:
        llm: LLMå®ä¾‹
        section_title: ç« èŠ‚æ ‡é¢˜
        section_content: ç« èŠ‚å†…å®¹
        expert_name: ä¸“å®¶åç§°

    è¿”å›:
        300å­—å·¦å³çš„ç« èŠ‚æ¦‚è¿°
    """
    prompt = f"""ä½ æ˜¯ä¸€ä½{expert_name},åˆšåˆšå®Œæˆäº†ä»¥ä¸‹ç« èŠ‚çš„ç¼–å†™ã€‚

ç« èŠ‚æ ‡é¢˜:{section_title}

ç« èŠ‚å†…å®¹:
{section_content}

è¯·ä¸ºè¿™ä¸ªç« èŠ‚ç¼–å†™ä¸€ä¸ª300å­—å·¦å³çš„æ¦‚è¿°,è¦æ±‚:
1. å‡†ç¡®æ¦‚æ‹¬ç« èŠ‚çš„æ ¸å¿ƒå†…å®¹å’Œè¦ç‚¹
2. çªå‡ºå…³é”®ä¿¡æ¯å’Œä¸»è¦è§‚ç‚¹
3. ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
4. å­—æ•°æ§åˆ¶åœ¨280-320å­—ä¹‹é—´
5. ç›´æ¥è¾“å‡ºæ¦‚è¿°å†…å®¹,ä¸éœ€è¦ä»»ä½•å‰ç¼€æˆ–æ ‡é¢˜

è¯·å¼€å§‹ç¼–å†™æ¦‚è¿°:"""

    messages = [SystemMessage(content=prompt)]
    response = safe_llm_invoke(llm, messages)

    return response.content.strip()


def should_continue_writing(state: DocumentState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­ç¼–å†™ç« èŠ‚"""
    completed_count = len(state.get("completed_sections", []))
    total_sections = len(state["outline"])

    if completed_count < total_sections:
        return "continue"
    else:
        return "done"


def compile_document(state: DocumentState) -> DocumentState:
    """ç›´æ¥æ‹¼æ¥æ‰€æœ‰ç« èŠ‚,ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£(ä¸è°ƒç”¨LLM)"""
    try:
        print(f"\n{'=' * 60}")
        print(f"ğŸ“¦ å¼€å§‹ç»„è£…æ–‡æ¡£...")
        print(f"{'=' * 60}\n")

        # ç»„è£…æ–‡æ¡£æ ‡é¢˜
        document_parts = [f"# {state['user_request']}\n\n"]

        # æŒ‰é¡ºåºæ‹¼æ¥æ‰€æœ‰ç« èŠ‚
        for section in state["completed_sections"]:
            document_parts.append(f"## {section['title']}\n\n")
            document_parts.append(f"{section['content']}\n\n")

        # ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
        final_document = "".join(document_parts)
        state["final_document"] = final_document

        print(f"âœ… æ–‡æ¡£ç»„è£…å®Œæˆ!")
        print(f"   æ€»å­—æ•°: {len(final_document)}")
        print(f"   ç« èŠ‚æ•°: {len(state['completed_sections'])}")
        print(f"   æ¦‚è¿°æ•°: {len(state.get('section_summaries', []))}\n")

        return state

    except Exception as e:
        print(f"âŒ æ–‡æ¡£ç»„è£…å‡ºé”™: {str(e)}")
        state["error_message"] = f"æ–‡æ¡£ç»„è£…é”™è¯¯: {str(e)}"
        raise


def save_to_word(content: str, filename: str, title: str = None, summaries: List[Dict[str, str]] = None):
    """
    å°†æ–‡æ¡£å†…å®¹ä¿å­˜ä¸ºWordæ ¼å¼

    å‚æ•°:
        content: æ–‡æ¡£å†…å®¹(Markdownæ ¼å¼)
        filename: è¾“å‡ºæ–‡ä»¶å
        title: æ–‡æ¡£æ ‡é¢˜
        summaries: ç« èŠ‚æ¦‚è¿°åˆ—è¡¨(å¯é€‰)
    """
    doc = Document()

    # 1. è®¾ç½®æ–‡æ¡£æ ‡é¢˜
    if title:
        heading = doc.add_heading(title, level=0)
        heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        doc.add_paragraph()  # æ·»åŠ ç©ºè¡Œ

    # 2. æ·»åŠ ç›®å½•
    doc.add_heading("ç›®å½•", level=1)

    # è§£æå†…å®¹è·å–ç« èŠ‚ä¿¡æ¯ç”¨äºç”Ÿæˆç›®å½•
    lines = content.split('\n')
    chapter_num = 1
    for line in lines:
        line = line.strip()
        if line.startswith('## '):
            chapter_title = line[3:].strip()
            doc.add_paragraph(f"{chapter_num}. {chapter_title}", style='List Number')
            chapter_num += 1

    doc.add_page_break()  # ç›®å½•ååˆ†é¡µ

    # 3. è§£æå¹¶æ·»åŠ æ­£æ–‡å†…å®¹
    for line in lines:
        line = line.strip()

        if not line:
            continue

        # å¤„ç†ä¸€çº§æ ‡é¢˜(# æ ‡é¢˜) - è·³è¿‡,å› ä¸ºå·²ä½œä¸ºæ–‡æ¡£æ ‡é¢˜
        if line.startswith('# '):
            continue

        # å¤„ç†äºŒçº§æ ‡é¢˜(## æ ‡é¢˜)
        elif line.startswith('## '):
            text = line[3:].strip()
            doc.add_heading(text, level=2)

        # å¤„ç†ä¸‰çº§æ ‡é¢˜(### æ ‡é¢˜)
        elif line.startswith('### '):
            text = line[4:].strip()
            doc.add_heading(text, level=3)

        # å¤„ç†æ™®é€šæ®µè½
        else:
            text = line.replace('**', '')
            if text:
                paragraph = doc.add_paragraph(text)
                paragraph_format = paragraph.paragraph_format
                paragraph_format.line_spacing = 1.5
                paragraph_format.space_after = Pt(6)

    # ä¿å­˜æ–‡æ¡£
    doc.save(filename)
    print(f"\n{'=' * 60}")
    print(f"ğŸ“„ Wordæ–‡æ¡£å·²ä¿å­˜åˆ°: {filename}")
    print(f"{'=' * 60}\n")


# ============================================
# 6. æ„å»ºå·¥ä½œæµå›¾
# ============================================

def create_document_workflow():
    """åˆ›å»ºæ–‡æ¡£ç”Ÿæˆå·¥ä½œæµ"""
    workflow = StateGraph(DocumentState)

    workflow.add_node("analyze", analyze_request)
    workflow.add_node("create_outline", create_outline)
    workflow.add_node("assign_sections", assign_sections)
    workflow.add_node("write_section", write_section)
    workflow.add_node("compile", compile_document)

    workflow.set_entry_point("analyze")
    workflow.add_edge("analyze", "create_outline")
    workflow.add_edge("create_outline", "assign_sections")
    workflow.add_edge("assign_sections", "write_section")

    workflow.add_conditional_edges(
        "write_section",
        should_continue_writing,
        {
            "continue": "write_section",
            "done": "compile"
        }
    )

    workflow.add_edge("compile", END)

    return workflow.compile()


# ============================================
# 7. ä¸»å‡½æ•°
# ============================================

def generate_document(
        user_request: str,
        api_key: str,
        api_url: str = "https://api.openai.com/v1",
        model: str = "gpt-4",
        max_retries: int = 3,
        timeout: int = 120,
        output_format: str = "docx"  # è¾“å‡ºæ ¼å¼
) -> str:
    """
    ç”Ÿæˆé•¿æ–‡æ¡£

    å‚æ•°:
        user_request: ç”¨æˆ·çš„æ–‡æ¡£éœ€æ±‚
        api_key: OpenAI API Key
        api_url: API åŸºç¡€URL(é»˜è®¤OpenAIå®˜æ–¹)
        model: ä½¿ç”¨çš„æ¨¡å‹(é»˜è®¤gpt-4)
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        timeout: è¶…æ—¶æ—¶é—´(ç§’)
        output_format: è¾“å‡ºæ ¼å¼,"docx" æˆ– "md"

    è¿”å›:
        ç”Ÿæˆçš„å®Œæ•´æ–‡æ¡£
    """
    if not api_key:
        raise ValueError("API Key ä¸èƒ½ä¸ºç©º")

    llm_config = LLMConfig(
        api_key=api_key,
        api_url=api_url,
        model=model,
        max_retries=max_retries,
        timeout=timeout
    )

    app = create_document_workflow()

    initial_state = {
        "user_request": user_request,
        "llm_config": llm_config,
        "completed_sections": [],
        "section_summaries": [],
        "error_message": None
    }

    print(f"\n{'=' * 60}")
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆæ–‡æ¡£")
    print(f"{'=' * 60}")
    print(f"ç”¨æˆ·éœ€æ±‚: {user_request}")
    print(f"API URL: {api_url}")
    print(f"æ¨¡å‹: {model}")
    print(f"è¾“å‡ºæ ¼å¼: {output_format.upper()}\n")

    try:
        final_state = app.invoke(initial_state)

        if final_state.get("error_message"):
            print(f"\nâš ï¸  è­¦å‘Š: {final_state['error_message']}")

        document = final_state.get("final_document", "æ–‡æ¡£ç”Ÿæˆå¤±è´¥")
        summaries = final_state.get("section_summaries", [])

        # ä¿å­˜æ–‡æ¡£
        if output_format.lower() == "docx":
            output_file = "generated_document.docx"
            save_to_word(document, output_file, user_request, summaries)
        else:
            output_file = "generated_document.md"
            with open(output_file, "w", encoding="utf-8") as f:
                # 1. æ·»åŠ æ ‡é¢˜
                f.write(f"# {user_request}\n\n")

                # 2. æ·»åŠ ç›®å½•
                f.write("## ç›®å½•\n\n")
                lines = document.split('\n')
                chapter_num = 1
                for line in lines:
                    line = line.strip()
                    if line.startswith('## '):
                        chapter_title = line[3:].strip()
                        f.write(f"{chapter_num}. {chapter_title}\n")
                        chapter_num += 1
                f.write("\n---\n\n")

                # 3. æ·»åŠ æ­£æ–‡ï¼ˆå»é™¤åŸæœ‰çš„ä¸€çº§æ ‡é¢˜ï¼‰
                for line in lines:
                    if not line.strip().startswith('# '):
                        f.write(line + '\n')

        return document

    except Exception as e:
        print(f"\nâŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {str(e)}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. API Key æ˜¯å¦æ­£ç¡®")
        print("2. API URL æ˜¯å¦å¯è®¿é—®")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("4. æ˜¯å¦éœ€è¦é…ç½®ä»£ç†")
        raise


# ============================================
# 8. ä½¿ç”¨ç¤ºä¾‹
# ============================================

if __name__ == "__main__":
    API_KEY = "sk-PagpyNwAitZjhGzzrWKUssACvvFk28U8O4dmypPxEkrRo2jh"
    API_URL = "https://xiaoai.plus/v1"

    user_request = "ç¼–å†™ä¸€ä»½å…³äºåŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­åº”ç”¨çš„ç ”ç©¶æŠ¥å‘Š"

    try:
        document = generate_document(
            user_request=user_request,
            api_key=API_KEY,
            api_url=API_URL,
            model="gpt-4o-mini",
            max_retries=3,
            timeout=120,
            output_format="docx"  # è¾“å‡ºä¸ºWordæ–‡æ¡£
        )

        print("æ–‡æ¡£é¢„è§ˆ(å‰500å­—):\n")
        print(document[:500] + "...\n")

    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")